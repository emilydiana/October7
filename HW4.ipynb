{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Create Assignment",
    "colab": {
      "name": "HW4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emilydiana/October7/blob/master/HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dkq9oiyfPQEr",
        "nbgrader": {
          "grade": false,
          "grade_id": "title",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "# CIS 545 Homework 4: Amazon Review Analysis and Classification\n",
        "\n",
        "Your main training set for this assignment is the text from 100,000 reviews from Amazon.com, their timestamps, and their star ratings. The high level goal of this homework is to use the textual and temporal data to predict the star ratings.\n",
        "\n",
        "**Adventurers beware!** Analyzing this data in `sklearn` will likely kill your kernel because it may need to store 1.9 billion values. So instead we will use the package [gensim](https://radimrehurek.com/gensim/) for analysis. gensim specializes in efficient implementations of common modeling techniques for big text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nB-65mi_PQEu",
        "colab": {}
      },
      "source": [
        "# install stuff\n",
        "%%capture\n",
        "!pip install -U gensim\n",
        "!pip install urllib2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3X5NKsi2Bwrh",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-0-0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Make sure the following line prints the up-to-date version of `gensim`, which at time of releasing this homework was version 3.8.1. If not, run the cell above again. If you don't do this, you may get different answers than us or have annoying error messages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XCZ2LpmRcSIX",
        "outputId": "d56b9dac-f25e-4ef1-91b2-5ac73ef5060e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# check gensim version\n",
        "import gensim\n",
        "gensim.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.8.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ngg1pmoZPQE4",
        "colab": {}
      },
      "source": [
        "# import stuff\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "from gensim import corpora\n",
        "from gensim.models import LsiModel, KeyedVectors\n",
        "from gensim.models.tfidfmodel import TfidfModel\n",
        "from gensim.models.nmf import Nmf\n",
        "\n",
        "import sklearn.model_selection as ms\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from datetime import *\n",
        "from operator import itemgetter\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79R84xo4FESL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!wget https://cis.upenn.edu/~cis545/data/reviews.dict\n",
        "!wget https://cis.upenn.edu/~cis545/data/train_reviews.mm\n",
        "!wget https://cis.upenn.edu/~cis545/data/train_times.npy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vBLPPKcePQE9",
        "colab": {}
      },
      "source": [
        "reviews_dict = corpora.Dictionary.load(\"reviews.dict\")\n",
        "reviews_bow = corpora.MmCorpus('train_reviews.mm')\n",
        "reviews_times  = np.load('train_times.npy')\n",
        "reviews_times.shape = (len(reviews_bow),1)\n",
        "y = np.vstack((np.repeat(1, 4000), np.repeat(2, 4000), np.repeat(3, 4000), np.repeat(4, 4000), np.repeat(5, 4000)))\n",
        "y = np.repeat(y, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKS2M3lcG2K1",
        "colab_type": "text"
      },
      "source": [
        "## Autograder Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "199wVVxjGznk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "STUDENT_PENN_ID = 46695085\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aojfs3k4G5ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import urllib.request\n",
        "import dill\n",
        "import base64\n",
        "\n",
        "api_endpoint = 'https://qvms14rjk2.execute-api.us-east-2.amazonaws.com/default/GallantGrader_v2'\n",
        "\n",
        "class TheGallantGrader: \n",
        "    def __init__(self, student_id, api_endpoint = api_endpoint, homework_id = '4'):\n",
        "        if student_id == None:\n",
        "            print('Error Autograder Not Setup: Enter your 8 digit PennID in the cell above.') \n",
        "        self.student_id   = str(student_id)\n",
        "        self.api_endpoint = api_endpoint\n",
        "        self.homework_id  = homework_id \n",
        "        \n",
        "    def grade(self, question_id, answer):\n",
        "        payload = {'student_id'   : self.student_id,\n",
        "                   'homework_id'  : self.homework_id,\n",
        "                   'test_case_id' : question_id,\n",
        "                   'answer'       : self.serialize(answer)}\n",
        "        params = json.dumps(payload).encode('utf-8')\n",
        "        request = urllib.request.Request(self.api_endpoint, \n",
        "                                         data    = params, \n",
        "                                         headers = {'content-type': 'application/json'})\n",
        "        try:\n",
        "            response = urllib.request.urlopen(request)\n",
        "            response_body = response.read().decode('utf-8')\n",
        "            print('{}'.format(response_body))\n",
        "        except:\n",
        "            print('Error: Grading request could not be completed.')\n",
        "\n",
        "    def serialize(self, obj):\n",
        "        byte_serialized = dill.dumps(obj)\n",
        "        return base64.b64encode(byte_serialized).decode(\"utf-8\")\n",
        "\n",
        "    def deserialize(self, obj):\n",
        "        byte_decoded = base64.b64decode(obj)\n",
        "        return dill.loads(byte_decoded)\n",
        "\n",
        "grader = TheGallantGrader(student_id = STUDENT_PENN_ID, homework_id = '4') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t0P6-gVuPQFE",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-0",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "## Step 0: Explore the format\n",
        "\n",
        "We will start with exploring the format of all of the data files that we imported above. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5gkoN7m7XvZ0",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-0-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 0.1: gensim dictionary (lexicon)\n",
        "\n",
        "Most data science over text has some form of vocabulary. Simply put, you need to decide which words your model will care about. Very rare words, misspellings, numbers, and urls are good candidates for exclusion, especially since if the model needs any form of normalization, the time complexity of such computations is at least linear in the size of the vocabulary, if not worse.\n",
        "\n",
        "A lexicon associates each word in the vocabulary with an index. Since words are repeated, the model can save space by using the index for every repetition and only linking the index with the string form once. A `gensim` dictionary is special in that it is very fast and allows bidirectional lookups, namely, word to index and index to word.\n",
        "\n",
        "After reviewing the [documentation](https://radimrehurek.com/gensim/corpora/dictionary.html), rewrite the right hand side of each line in the cell below with the answers to these questions.\n",
        "\n",
        "1. In the `gensim` dictionary `reviews_dict`, what is the index of \"best\"? Look it up and store it in a variable named `best`. To clarify, if you find that 42 is the index of \"best\", change the line below so that it sets `best` equal to 42. Of course, you can do this with `best = 42` and earn full points, but it is a litte better to reuse the command with which you found the index. For example, if the `gensim` dictionary worked like a list of strings, you could do it with  \n",
        "`best = reviews_dict.iloc('best')`.\n",
        "2. What word belongs to index 1911? Look it up and store it in a variable named `onenineoneone`.\n",
        "3. What happens when you evaluate `reviews_dict[i]` for some variable `i`? If this returns the word associated with that index, set `idx2word` to `True`. Otherwise, set it to `False`. For example, if `reviews_dict['best']` equals `best`, `idx2word` should be `False`, but if `reviews_dict[1911]` equals `onenineoneone`, `idx2word` should be `True`.\n",
        "\n",
        "Hint: `token2id('best')` and `id2token(1911)` didn't work for me either. Keep trying!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JgQ1DMnnPQFI",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-0-1",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# answer 0.1\n",
        "best = reviews_dict.doc2idx(['best'])[0]\n",
        "onenineoneone = reviews_dict.get(1911)\n",
        "idx2word = (reviews_dict[1911] == onenineoneone)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz5ndlKlHZRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 0.1: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"0.1\", answer = (best, onenineoneone, idx2word) )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pAVMO7GZPQFp",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-0-2",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### Step 0.2: Look up individual reviews\n",
        "\n",
        "`gensim` represents everything in a **sparse** way. Namely, the representation of a review will be a variable-size list that contains counts of the words that _are present_ in the review. A **dense** representation, on the other hand, such as a matrix, would, in addition to the present words, contain zero counts for all of the words that are not in that particular review. For some examples, see [this tutorial](https://radimrehurek.com/gensim/auto_examples/core/run_core_concepts.html).\n",
        "\n",
        "But the optimizations don't stop there! `gensim` also saves space by not directly storing where one document ends and another begins. Such an implementation decision encourages users to stream the dataset through the user's pipeline, rather than attempt to read large chunks into memory. Put another way, you can iterate through the dataset using a loop or vectorized function, but you cannot index. In code:\n",
        "\n",
        "`for doc in corpus` works!\n",
        "\n",
        "`corpus[1911]` does not work!\n",
        "\n",
        "On some occasions, though, it would be convenient for us to, say, look up the 1911th document directly.\n",
        "\n",
        "So let's implement a function that iterates through the `gensim` `corpus`, collects every document whose index appears in `indices`, and returns that list of documents (subset of the dataset). For example, say we want the documents with the following indices: `indices = [0, 19, 11, 0]`. Then `lookup_docs` should return the 1st, 12th, and 20th documents, in that order.\n",
        "\n",
        "To emphasize, if an index appears multiple times in `indices`, just return one copy. And for consistency with our autograder, please return the documents in order of increasing index. That would be be like `corpus[0]`, then `corpus[11]`, then `corpus[19]` in our example. Of course, that way to reference them doesn't work, though!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-s5GeN5SKq2o",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-0-2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 0.2 \n",
        "def lookup_docs(corpus, indices):\n",
        "  list = []\n",
        "  count = 0\n",
        "  for doc in corpus:\n",
        "    if count in indices:\n",
        "      list.append(doc)\n",
        "    count +=1\n",
        "  return list\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nj5S7Kyy3yf8",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-0-2-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Once you have written `lookup_docs`, you may run the cell below (no modification needed) to see how documents are represented in a gensim [corpus](https://radimrehurek.com/gensim/corpora/mmcorpus.html). In each review, `gensim` stores a tuple of size 2 for each distinct word in the review. The first number in the tuple is the index of the word in the dictionary and the second number in the tuple is the count of the times that word appeared in that review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3diZMuUOPQFx",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-0-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "245a2e10-7f4f-4382-fa53-54d2115f1ee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "indices = [10,18]\n",
        "docs = lookup_docs(reviews_bow, indices)\n",
        "\n",
        "print(docs[0])\n",
        "print(docs[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(2, 1.0), (21, 1.0), (23, 1.0), (55, 1.0), (72, 1.0), (79, 1.0), (108, 1.0), (121, 1.0), (138, 1.0), (144, 1.0), (176, 1.0), (238, 1.0), (258, 1.0), (266, 3.0), (267, 1.0), (268, 2.0), (269, 1.0), (270, 1.0), (271, 1.0), (272, 3.0), (273, 1.0), (274, 1.0), (275, 1.0), (276, 1.0), (277, 1.0), (278, 2.0), (279, 1.0), (280, 1.0), (281, 1.0), (282, 1.0)]\n",
            "[(5, 1.0), (11, 2.0), (14, 2.0), (17, 1.0), (24, 7.0), (30, 2.0), (31, 1.0), (49, 1.0), (50, 2.0), (51, 1.0), (60, 1.0), (71, 2.0), (82, 1.0), (87, 2.0), (105, 3.0), (144, 2.0), (164, 1.0), (165, 1.0), (177, 1.0), (179, 1.0), (181, 1.0), (186, 1.0), (218, 4.0), (224, 1.0), (233, 1.0), (241, 1.0), (258, 1.0), (348, 1.0), (373, 1.0), (379, 1.0), (382, 1.0), (383, 2.0), (384, 1.0), (385, 2.0), (386, 1.0), (387, 3.0), (388, 1.0), (389, 1.0), (390, 2.0), (391, 1.0), (392, 1.0), (393, 1.0), (394, 1.0), (395, 1.0), (396, 1.0), (397, 1.0), (398, 1.0), (399, 1.0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bjl67ZWq4tZm",
        "nbgrader": {
          "grade": true,
          "grade_id": "hidden-test-0-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 0.2: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"0.2\", answer = docs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gn0lzmyPaP5j",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-0-3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 0.3: Make reviews more human-readable\n",
        "\n",
        "Now, we would like you to write a function that takes a `gensim` bag of words document and its corresponding dictionary as input and returns a \"translated\" version that is more readable. The reviews are already represented as bags of words, so recall that you cannot recover the order of the words in the reviews. But, we would like you to spell out the repeats of each word. So, if the original review were \"to be or not to be\", `reviews_bow` would have something like:\n",
        "\n",
        "`[(0, 2.0), (1, 1.0), (2, 1.0), (3, 2.0)]`\n",
        "\n",
        "and we would like you to return the string\n",
        "\n",
        "`\"be be not or to to\"`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H-XXZOTtaiAM",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-0-3",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "35f2b076-7ac5-4655-9f52-ddc8d1af9ea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# answer 0.3\n",
        "def translate_review(review, reviews_dict):\n",
        "    str=\"\"\n",
        "    for (elem, num) in review:\n",
        "      for i in range(0,int(num)):\n",
        "        str = str + reviews_dict[elem] + ' '\n",
        "    return str.strip()\n",
        "\n",
        "readable_1 = translate_review(docs[0], reviews_dict)\n",
        "print(readable_1)\n",
        "\n",
        "readable_2 = translate_review(docs[1], reviews_dict)\n",
        "print(readable_2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "also hard just will replac use pet anyth time go stop want product cat cat cat cooler cut cut describ found groomer hair hair hair hot long need never poor shave shave shed summer though weather\n",
            "away chewer chewer destroy destroy fast kong kong kong kong kong kong kong mix mix money tore toy toy tri dog regular regular worth bought bought one one one go go fine first take within chew rip like like like like probabl thing care product look two pound big bone bone chase dachshund dachshund durabl extrem extrem extrem five flyer frisbe frisbe habit mine minut power pretti realli sure version wobbler\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCs7pGm_JPvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 0.3: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"0.3\", answer =  (translate_review, dict(reviews_dict)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-BJG91UHPQG6",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-0-4",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### Step 0.4: Parse review times\n",
        "\n",
        "It might be useful in predicting the scores of the reviews to know when the reviews were written. In this dataset, the day of the review was recorded as the number of seconds that passed between midnight on January 1, 1970 (the beginning of time for many computer systems) and the time the review was created. This may be efficient because it is one integer, but it is not very convenient. So we are going to convert these int objects to [datetime](https://docs.python.org/3/library/datetime.html) objects:\n",
        "\n",
        "**Do not change `review_times` in any way. Work with other variables instead.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pjYIR8V960Hb",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-0-4-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Step 0.4.1: Convert times vector\n",
        "\n",
        "The `convert_times` function should take in the entire `review_times` vector at once. It should return a new pandas `Series` object made from `review_times` but the entries should be of type `datetime` or `Timestamp`.\n",
        "\n",
        "Hint: You might find `datetime.fromtimestamp` to be useful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2AvvxOpjPQG9",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-0-4-1",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# answer 0.4.1\n",
        "def convert_times(reviews_times):\n",
        "  times = pd.Series(np.ndarray.tolist(reviews_times))\n",
        "  times = times.apply(lambda x : datetime.fromtimestamp(x[0]))\n",
        "  return times"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJuU3--pKap5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converted_times = convert_times(reviews_times)\n",
        "print(\"converted_times is a\", type(converted_times))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBVsOFvFKTYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 0.4: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"0.4\", answer = (str(type(converted_times)), str(type(converted_times[0])), str(type(converted_times[1])), str(converted_times[1])))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fyKf4Ryt7O6H",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-0-4-2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Step 0.4.2: Time math\n",
        "\n",
        "The `days_before` function should take in one time value (after applying `convert_times`) and return a new time value that is exactly `offset` days before the input.\n",
        "\n",
        "Hint: You might find `timedelta` to be useful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eYEkmo2d6NQn",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-0-4-2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 0.4.2\n",
        "def days_before(time_item, offset):\n",
        "  return (time_item - timedelta(days=offset))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7tJgAcauPQH1",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-0-4-2",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "display(converted_times[0])\n",
        "forty_days_before_review_times_0 = days_before(converted_times[0], 40)\n",
        "display(forty_days_before_review_times_0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89ckXfd7LCkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 0.4.2: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"0.4.2\", answer = str(forty_days_before_review_times_0))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tywL0VjAbYMY",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "## Step 1: How many components?\n",
        "\n",
        "We will need to perform dimesionality reduction on our dataset before we can proceed further with the supervised task of predicting the star ratings. One of the greatest benefits of gensim is that it can decompose a sparse dataset directly. Indeed, they post some impressive numbers about their SVD speed [here](https://radimrehurek.com/gensim/models/lsimodel.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u3W2ZOv0nlrE",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 1.1: PCA on raw counts\n",
        "\n",
        "We are first going to choose too many components deliberately, just to make sure that we see the whole picture. But note that 1000 components would still require us to store 100 million numbers. So that is probably too big for convenient exploration of the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sxXINIEFABa6",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-1-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Step 1.1.1: Train the PCA model\n",
        "\n",
        "Train a gensim `LsiModel` on `reviews_bow` using `reviews_dict` as the dictionary and 1000 components. This magic number is provided as `max_cutoff`. The API is [here](https://radimrehurek.com/gensim/models/lsimodel.html).\n",
        "\n",
        "**This step took about 4 minutes for my Colab instance to complete.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rDRc0IRfbYMe",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-1-1-1",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# answer 1.1.1\n",
        "\n",
        "max_cutoff = 1000\n",
        "model = LsiModel(corpus = reviews_bow, id2word = reviews_dict, num_topics = max_cutoff)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Skq9LPDbYMn",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-1-2",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "#### Step 1.1.2: Extract the singular values\n",
        "\n",
        "Look at the [API page](https://radimrehurek.com/gensim/models/lsimodel.html) to figure out how to get the singular values from a trained model. Feed those and `max_cutoff` to the `plot_variance_vs_components` function, which you do not have to edit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pfDFbW_qbYMq",
        "colab": {}
      },
      "source": [
        "def plot_variance_vs_components(singular_values, cutoff):\n",
        "    evr = np.array([singular_values[i]**2 / sum(singular_values**2) for i in range(cutoff)])\n",
        "    var = np.cumsum(evr*100)\n",
        "    plt.ylabel('% Variance Explained')\n",
        "    plt.xlabel('# of Components')\n",
        "    plt.title('PCA Analysis')\n",
        "    plt.style.context('seaborn-whitegrid')\n",
        "    plt.plot(var)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HQHACc0ow6K5",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-1-1-2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 1.1.2\n",
        "singular_values = model.projection.s\n",
        "singular_values\n",
        "plot_variance_vs_components(singular_values, max_cutoff)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WLgVssiNbYMy",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-1-2-1",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "The good news is this curve is very steep in the beginning, which shows that a lot of information is conveyed in the first components. However, there is no plateau that we can use to choose a cutoff!\n",
        "\n",
        "**So, let's go back to the dataset. Are the numbers in `reviews_bow` distributed sensibly?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FqZ4vnCPn6O-",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 1.2: TF-IDF -- a better distribution\n",
        "\n",
        "The function below allows us to visualize the distribution of the values in the bag of words. You do not need to edit it. Recall that there are no zero values by nature of the sparse representation. The function has two convenient features:\n",
        "\n",
        "1. It allows you to transform the values uniformly using an optional second argument.\n",
        "2. By subtracting the mean, the new mean will line up with $x=0$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "li80IItWzgsK",
        "colab": {}
      },
      "source": [
        "def plot_values(reviews, function=None):\n",
        "    values = []\n",
        "    for doc in reviews:\n",
        "        for (word, score) in doc:\n",
        "            if not function: values.append(score)\n",
        "            else:            values.append(function(score))\n",
        "\n",
        "    plt.hist(values - np.mean(values), bins='auto')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sJRiDUPBfAiK",
        "colab": {}
      },
      "source": [
        "plot_values(reviews_bow)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t8fdmx8CfQbY",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-2-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "It appears that our values are very highly skewed. Therefore, minmax and standard scaling would not (yet) be appropriate. Let's see if we can make it look better by log scaling the values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3W-hAN9ZgMZw",
        "colab": {}
      },
      "source": [
        "plot_values(reviews_bow, np.log)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bF81W6ETiivP",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-2-2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "It is a little better, but only a little bit. Perhaps a double log?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Va1byrsCg-pa",
        "colab": {}
      },
      "source": [
        "plot_values(reviews_bow, lambda x: np.log(np.log(x+1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xKpC3bnGg4Yo",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-2-3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Still not so good. There are (at least) two outstanding issues with this distribution:\n",
        "\n",
        "1. The vast majority of words only occur once per review.\n",
        "2. In the rare case that a word occurs more than once, we can't tell if that is because it is especially important or because it is a common word, like a stop word.\n",
        "\n",
        "Therefore, we are going to convert our counts into [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) scores. Luckily, this is built in to `gensim` so this can be done in a couple lines of code. The API is [here](https://radimrehurek.com/gensim/models/tfidfmodel.html). Complete the function below that converts the data to TF-IDF scores. Note: that is a two step process. First, you need to initialize and fit a TF-IDF model to `reviews_bow`. (use default values for all hyperparameters **EXCEPT you should set `normalize=True`**). Then, you should apply your TF-IDF model to `reviews_bow` to transform it. Return the new version of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dhlmCiiTzgph",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-1-2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 1.2\n",
        "def make_tfidf(reviews_bow):\n",
        "    model = TfidfModel(reviews_bow, normalize=True)\n",
        "    new_model = model[reviews_bow]\n",
        "    return new_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vFNBR3JTZDYs",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-1-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "reviews_tfidf = make_tfidf(reviews_bow)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kN1R8-annaHN",
        "colab": {}
      },
      "source": [
        "plot_values(reviews_tfidf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgRik0wfn8wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 1.2: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"1.2\", answer = str(type(reviews_tfidf)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4XxMZv1Skwkn",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-2-4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "This should look a lot better. Log scaling it may make the distribution look a bit more symmetrical, but this would come at the cost of collapsing some distinctions in the right tail, so we will not do it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wADH4r2VoIQE",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 1.3: PCA on TF-IDF scores\n",
        "\n",
        "Let's try the PCA again and plot a new variance versus number of components."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eunxl15fzg0U",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-1-3",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "3fe15398-ff24-4842-8aad-159085a9ec19"
      },
      "source": [
        "# answer 1.3\n",
        "model_tfidf = LsiModel(corpus = reviews_tfidf, id2word = reviews_dict, num_topics = max_cutoff)\n",
        "singular_values_tfidf = model_tfidf.projection.s\n",
        "plot_variance_vs_components(singular_values_tfidf, max_cutoff)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-75242a5e919a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLsiModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msingular_values_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplot_variance_vs_components\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingular_values_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cutoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'max_cutoff' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vrhnv0Qh5RVQ",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-1-3-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "If anything, this graph is less helpful than before. **So, instead, we would like to use downstream performance of the classifier to tune this hyperparameter.** So let's build the remaining pieces that we need."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0ErKk3gaPQIR",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-2",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "## Step 2: Interface with sparse representations\n",
        "\n",
        "To get the real benefit of dimensionality reduction, it is important to consider which pieces of the decomposition are actually needed. Then, we can simply throw away the rest. To help you become familiar with the different pieces we will fully decompose and reconstruct the toy dataset of 5 computer science and 4 math article titles using `gensim`. It will be important later on that you only apply the functions that you write in this section to the pieces that you need on the big dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0hhoUvIZpr4d",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-2-0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 2.0: The sparse toy dataset\n",
        "\n",
        "After lower casing, tokenizing, and stop wording, the corpus looks like `titles` in the cell below. Then, we create a dictionary and a sparse document-term matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XUluV0evPQIU",
        "outputId": "da9fe680-05d5-47fb-f273-4c38cb667c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "titles = [['human', 'interface', 'computer'],\n",
        "          ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
        "          ['eps', 'user', 'interface', 'system'],\n",
        "          ['system', 'human', 'system', 'eps'],\n",
        "          ['user', 'response', 'time'],\n",
        "          ['trees'],\n",
        "          ['graph', 'trees'],\n",
        "          ['graph', 'minors', 'trees'],\n",
        "          ['graph', 'minors', 'survey']]\n",
        "\n",
        "titles_dict = corpora.Dictionary(titles)\n",
        "titles_bow = [titles_dict.doc2bow(title) for title in titles]\n",
        "display(titles_bow)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[[(0, 1), (1, 1), (2, 1)],\n",
              " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
              " [(2, 1), (5, 1), (7, 1), (8, 1)],\n",
              " [(1, 1), (5, 2), (8, 1)],\n",
              " [(3, 1), (6, 1), (7, 1)],\n",
              " [(9, 1)],\n",
              " [(9, 1), (10, 1)],\n",
              " [(9, 1), (10, 1), (11, 1)],\n",
              " [(4, 1), (10, 1), (11, 1)]]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gCJTCgU0PQIc",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-2-1",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### Step 2.1: Sparse to dense\n",
        "\n",
        "To get the term-document matrix that we have seen in lecture, we need to convert this matrix to its dense form. Write a function `densify` that takes as input:\n",
        "\n",
        "1. a sparse matrix in the format of `titles_bow` above\n",
        "3. an integer number of columns\n",
        "\n",
        "and returns a NumPy array. Note that `titles_bow` is a document-term matrix, not a term-document matrix, so we transpose it in the test cell to show the matrix from lecture (with the rows and columns slightly reordered).\n",
        "\n",
        "You may not use the `corpus2dense` function from `gensim`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iuzFAAekPQId",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-2-1",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# answer 2.1\n",
        "def densify(sparse, columns):\n",
        "    array = np.zeros((len(sparse),columns))\n",
        "    i=0\n",
        "    for doc in sparse:\n",
        "      for (elem, freq) in doc:\n",
        "        array[i, elem] = freq\n",
        "      i+=1\n",
        "    return array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0PvkEMcyPQIi",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-2-1-1",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "td = densify(titles_bow, len(titles_dict)).transpose()\n",
        "print(td)\n",
        "print(td.shape)\n",
        "print (titles_bow)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1kR4wHdMX_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 2.1: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"2.1\", answer = (td[4].tolist(), round(sum(sum(td))).item(), str(type(td))))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O5axMVwhPQN6",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-2-2",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "### Step 2.2: Toy PCA reconstruction\n",
        "\n",
        "In the cell below, write a function called `reconstruction` that takes as input:\n",
        "\n",
        "1. a sparse matrix\n",
        "2. a gensim dictionary\n",
        "2. a cutoff for PCA\n",
        "\n",
        "The function should compute an `LsiModel` and reconstruct the original matrix. \n",
        "\n",
        "**There is something unexpected about the correct solution to this part!**\n",
        "\n",
        "Before turning to Piazza, print the dimensions of the pieces that you are working with, using `.shape`. What are the dimensions of the original? What are the dimensions of the outputs from `LsiModel`? How can you multiply the pieces together to get a match? You can do this! We have faith in you!\n",
        "\n",
        "Note that there could be a loss because the function only computes the part of the singular value decomposition that is needed according to `cutoff`. So after reconstructing, let's quantify the loss: compute the difference between the reconstructed matrix and the original. Then, take the Frobenius norm of that difference matrix. Divide by the Frobenius norm of the original. Make this the return value for the function.\n",
        "\n",
        "Hint: The right singular vectors ($V$ or `model[sparse]`) already contain the singular values ($S$ or `model.projection.s`) so don't include them again!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UtJAyg6SPQN8",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-2-2",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# answer 2.2\n",
        "def PCA_reconstruction(sparse, gsdict, cutoff):\n",
        "    dense_1 = densify(sparse, len(gsdict))\n",
        "    model = LsiModel(corpus = sparse, id2word = gsdict, num_topics = cutoff)\n",
        "    dense_2 = densify(model[sparse], cutoff)\n",
        "    temp = model.projection.u.transpose()\n",
        "    reconstructed = dense_2 @ temp\n",
        "    return ((np.linalg.norm (dense_1 - reconstructed))/(np.linalg.norm(dense_1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nn70AE0JPQOO",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-2-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "for cutoff in range(2,10):\n",
        "    error = PCA_reconstruction(titles_bow, titles_dict, cutoff)\n",
        "    print(\"The reconstruction error with\", cutoff, \"components on the the toy dataset is\", error)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCuuw47PMSMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 2.2: Run this to get your score. ##\n",
        "\n",
        "answer1 = PCA_reconstruction(titles_bow, titles_dict, 2)\n",
        "answer2 = PCA_reconstruction(titles_bow, titles_dict, 6)\n",
        "grader.grade(question_id = \"2.2\", answer = (answer1.item(), answer2.item()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Rn49PaMlY-M",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-3",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "## Step 3: Choose the number of components via the downstream task\n",
        "\n",
        "Using classification performance to choose the number of components is arguably even better than the plateau method, because we are optimizing directly on the downstream task rather than something intrinsic to the dataset. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qAbvT5iqrCI8",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-3-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 3.1 Train the random forest\n",
        "\n",
        "The code below:\n",
        "\n",
        "1. combines the review TF-IDF scores and the date information into one dataset\n",
        "2. splits off 20% of the training data as a validation set\n",
        "3. Initializes a random forest with 70 estimators\n",
        "\n",
        "To finish the pipeline, add the code that trains the [random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and computes the accuracy on the test set. Return that number as a real value between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "acWFX8EsrCdM",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-3-1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 3.1\n",
        "def evaluate_model(X, review_times, y):\n",
        "    X = np.hstack((X, review_times))\n",
        "    X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.2, random_state = 1911)\n",
        "    rfor = RandomForestClassifier(n_estimators=70, random_state=1911)\n",
        "    model = rfor.fit(X_train, y_train)\n",
        "    return (rfor.score(X_test, y_test)) #check this\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XIy40pHYrClZ",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-3-2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 3.2 Compare performance\n",
        "\n",
        "In the cell below, finish the `evaluate_cutoffs` function. The missing code should train an `LsiModel`, compute the $V$ matrix (right singular vectors), call `densify` on that, and pass the dense matrix to evaluate model. Store all of your accuracies in a list named `results`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VsfJ3KIglY-S",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-3-2",
          "locked": false,
          "schema_version": 3,
          "solution": true
        },
        "colab": {}
      },
      "source": [
        "# answer 3.2\n",
        "def evaluate_cutoffs(X_orig, X_dict, X_times, y, cutoffs):\n",
        "    results = []\n",
        "    for cutoff in cutoffs:\n",
        "        np.random.seed(1911)\n",
        "        model = LsiModel(corpus = X_orig, num_topics = cutoff, id2word = X_dict)\n",
        "        right_sv = model[X_orig]\n",
        "        dense_right_sv=densify(right_sv, cutoff)\n",
        "        accuracy = evaluate_model(dense_right_sv, X_times, y)\n",
        "        results.append(accuracy)\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n6Wrw13-SXbE",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-3-2-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**WARNING: The following cell should take a while to complete.**\n",
        "\n",
        "Each of the 30 models takes a minute or two, and the later ones are bigger (correspondingly slower). Therefore we are going to analyze your output for grading. Once you have a good idea about the best performing model in this set, give us that accuracy and we will check if it is in the expected range."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VDAI7SAWbD1K",
        "colab": {}
      },
      "source": [
        "results = evaluate_cutoffs(reviews_tfidf, reviews_dict, reviews_times, y, range(10,40))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7Gmo6qmvlY-f",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-3-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false
        },
        "colab": {}
      },
      "source": [
        "display(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FexYM3kGNXdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 3.2: Run this to get your score. ##\n",
        "\n",
        "answer = max(results)\n",
        "grader.grade(question_id = \"3.2\", answer = (len(results), answer.item()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uxvkclGxs_s5",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Step 4: k-means clustering\n",
        "\n",
        "So far, we have one system for classifying the number of stars in a review. But maybe there are patterns that are only true for some subsets of the data? To uncover this, we would like to cluster the reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3Aaxrh3KuRZH",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 4.0: Which version of the data?\n",
        "\n",
        "Recall that k-means has a runtime complexity with the strongest term proportional to:\n",
        "\n",
        "(# of dimensions)(# of points)(# of clusters)(# of iterations)(# of restarts)\n",
        "\n",
        "Let's focus on the first three terms. The number of points is 100,000, which is pretty large. Therefore, we will have to be especially careful with the number of dimensions and clusters.\n",
        "\n",
        "In the previous steps, we generated dimensionality-reduced versions of the dataset. While they did not capture a large, satisfying percentage of the variance in the reviews, the random forest classifier hinted that relatively few principal components were enough to capture the relevant variance for classifying star ratings. Specifically, my random forest seemed to hit a performance ceiling somewhat before reaching 40 components. Therefore, let's use the TF-IDF version with 40 components.\n",
        "\n",
        "In the cell below, add the code that trains the `LsiModel`, computes the right singular vectors, and densifies these projections. Store this dimensionality-reduced dataset as `X`. What are the expected dimensions?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3xSUnNABs0ux",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-4-0",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 4.0\n",
        "cutoff = 40\n",
        "np.random.seed(1911)\n",
        "model_tfidf = LsiModel(corpus = reviews_tfidf, id2word = reviews_dict, num_topics = cutoff)\n",
        "X = densify(model_tfidf[reviews_tfidf], cutoff)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NwoSMd8e4inF",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-4-0",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYxq0eSkrNZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 4.0: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"4.0\", answer = X.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zGtBAayHyFOP",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 4.1: Collect SSWs\n",
        "\n",
        "In the cell below, the function called `test_cluster_size` iterates over the numbers of clusters in the array `num_clusters`. The function takes as input (1) the data as a matrix and (2) the `num_clusters` array. \n",
        "\n",
        "Add the missing code that should cluster the data using k-means and store the $SS_W$ values.\n",
        "\n",
        "Note from the `sklearn.cluster` documentation on __[k-means](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)__:\n",
        "\n",
        "Attributes:\t\n",
        "* `cluster_centers_` : array, [n_clusters, n_features]\n",
        " Coordinates of cluster centers\n",
        "\n",
        "* `labels_` :\n",
        "Labels of each point\n",
        "\n",
        "* `inertia_` :\n",
        "Sum of squared distances between data points and their cluster centers\n",
        "\n",
        "Finally, return a list of $SS_W$ values using the attributes above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I4aay58hs0xr",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-4-1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 4.1\n",
        "def test_cluster_size(data, num_clusters):\n",
        "    scores = []\n",
        "    for i in num_clusters:\n",
        "        km = KMeans(n_clusters=i, init='k-means++', n_init=30, max_iter=10, \n",
        "                    tol=1e-4, random_state=1911, n_jobs=1).fit(data)\n",
        "        ssw = km.inertia_\n",
        "        scores.append(ssw)\n",
        "    return scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x1Nn47RSV7iO",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-1-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "The cell below also takes a while to run because it is going to cluster the data 38 times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fjk1iQIkZjUz",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-4-1-1",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "num_clusters = range(2, 40)\n",
        "ssws41 = test_cluster_size(X, num_clusters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mM73T_791b5F",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-4-1-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "display(ssws41)\n",
        "if (len(ssws41) != 38):\n",
        "    raise ValueError(\"Did not compute SSWs for the given values of k.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6ZNeae8N0vK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 4.1: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"4.1\", answer = [item.item() for item in ssws41] )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kF4dj3Jc0yx5",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 4.2: Find the elbow?\n",
        "\n",
        "The following provided code helps you plot the number of clusters (from 2 to 40) versus $SS_W$. You do not need to modify these two cells.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8Xu7aLb1s00U",
        "colab": {}
      },
      "source": [
        "def plot_clusters(num_clusters, distortions):\n",
        "    plt.figure()\n",
        "    plt.xlabel('Number of Clusters')\n",
        "    plt.ylabel('Distortion')\n",
        "    plt.title('Cluster Analysis')\n",
        "    plt.style.context('seaborn-whitegrid')\n",
        "    plt.plot(num_clusters, distortions)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5jjS_CQzXUQY",
        "colab": {}
      },
      "source": [
        "plot_clusters(num_clusters, ssws41)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CZonCmMEWvbH"
      },
      "source": [
        "Do you see a clear \"elbow\" in this graph??\n",
        "\n",
        "Probably not.\n",
        "\n",
        "Just so we can test your solution, we will mathematically define elbow as:\n",
        "\n",
        "$$\\hat{k}_{SSW} = \\underset{k}{\\operatorname{argmin}} (SS_W(k) - SS_W(k+1))$$\n",
        "\n",
        "This is not a perfect mathematical definition because it does not take into account how much $SS_W$ dropped before the selected point. But for this dataset, it does provide one consistent answer.\n",
        "\n",
        "In the cell below, complete the function that implements this mathematical definition. Note that we only pass in the list of distortion values. \n",
        "\n",
        "**So the function should return the index of the selected number of clusters!!**\n",
        "\n",
        "Look at the visible test for this subsection to see how we ultimately assign the value of $k$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lyWFRaX8W1OB",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-4-2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 4.2\n",
        "def sharpest(distortions):\n",
        "    offset_0 = distortions[0:len(distortions)-1]\n",
        "    offset_1 = distortions[1:len(distortions)]\n",
        "    diff = np.subtract(offset_0, offset_1).tolist()\n",
        "    minpos=diff.index(min(diff))\n",
        "    return minpos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NodsP9TEXnBm",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-4-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "khat42 = num_clusters[sharpest(ssws41)]\n",
        "print(\"I have chosen to have\", khat42, \"clusters.\")\n",
        "if ((khat42 < 2) or (khat42 > 39)):\n",
        "    raise ValueError('k hat is not in the right range')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LytpCo6OXU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 4.2: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"4.2\", answer = khat42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RkZhBXB12L0e",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 4.3: The Variance Ratio Criterion\n",
        "\n",
        "Perhaps we can shift to a different cluster evaluation metric that gives a more satisfying suggestion for the number of clusters.\n",
        "\n",
        "Recall the Variance Ratio Criterion ($VRC$), given by\n",
        "\n",
        "$$ VRC(k) = \\frac{SS_B}{k-1} / \\frac{SS_W}{N - k}$$\n",
        "\n",
        "where $SS_B$ is the sum of squared distance between the cluster centers and the grand mean (calculated per data point), $k$ is the number of clusters, $SS_W$ is the sum of squared distance between data points and their assigned cluster centers, and $N$ is the number of data points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IHvHvApo2vT7",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-3-0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Step 4.3.0: The grand mean\n",
        "\n",
        "Before we apply the full formula, please compute the grand mean of the dataset. What does this represent?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NNY-f2PT2v7w",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-4-3-0",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 4.3.0\n",
        "temp = pd.DataFrame(X)\n",
        "grand_mean = temp.mean(axis=0).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8wS0k69nHA1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "719d5561-4ff6-4742-f5de-67712eca4a35"
      },
      "source": [
        "gm = KMeans(n_clusters=1, init='k-means++', n_init=30, \n",
        "                    tol=1e-4, random_state=1911, n_jobs=1).fit(X).cluster_centers_[0]\n",
        "print(gm - grand_mean)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-6.93889390e-16  1.07661276e-16 -7.82793969e-17 -5.36680075e-18\n",
            " -6.11490025e-17  2.60208521e-17 -6.76542156e-17  9.32413868e-18\n",
            " -6.61363325e-18  7.75204553e-18 -5.90890184e-17  2.16840434e-19\n",
            " -4.33680869e-19 -3.53449908e-17  1.24683250e-17  8.29414662e-18\n",
            "  2.11419424e-18 -1.11672824e-17  3.43149988e-17  7.15573434e-18\n",
            " -8.34835673e-18 -3.03576608e-18 -2.93818789e-17 -6.85419061e-18\n",
            " -8.37546178e-18 -1.47451495e-17 -2.30935063e-17  3.46944695e-18\n",
            " -3.60497222e-18  2.33645568e-17  2.08708918e-18 -2.60208521e-18\n",
            "  4.09286320e-18 -1.93123512e-19 -5.10930274e-17 -2.48553348e-17\n",
            "  6.23416249e-18 -1.91361683e-17 -7.91467586e-18 -5.31259065e-18]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9QZjpw-paikZ",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-3-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Step 4.3.1: Interpret the grand mean\n",
        "\n",
        "The grand mean is the text of the \"average\" review on Amazon. Let's figure out what that is a bit more precisely for this dataset. The function below finds real data points, i.e. real reviews, that are the closest neighbors to a given vector (`item`). `X_proj` is the dataset, `mask` is a list of booleans stating whether each item in the dataset is an eligible neighbor (we need this later), and `k` is the number of neighbors we would like to find. Write the missing code which should:\n",
        "\n",
        "1. Normalize `item` by its Frobenius norm.\n",
        "2. Loop through the dataset. Exclude the items that have a corresponding `False` value in `mask`.\n",
        "3. For each eligible item in the dataset, compute the [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) with `item`. Remember that you have normalized `item` but you will still need to normalize the other vector. \n",
        "4. Store the cosines in a list. It may be useful to put the cosines in tuples with the corresponding indices, but you don't have to do it this way.\n",
        "5. Find the `k` highest cosine values.\n",
        "6. Return the indices corresponding to these highest cosines. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cD_pwHiqa5HY",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-4-3-1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 4.3.1\n",
        "def k_nearest_neighbors(X_proj, mask, item, k):\n",
        "    item_norm = item / np.linalg.norm(item)\n",
        "    X = X_proj[mask]\n",
        "    cos=[]\n",
        "    for elem in X:\n",
        "      if (np.linalg.norm(elem) > 0):\n",
        "        elem = elem / np.linalg.norm(elem)\n",
        "      sim = np.dot(elem,item_norm)\n",
        "      cos.append(sim)\n",
        "    indices = sorted(range(len(cos)), reverse=True, key=lambda x: cos[x])\n",
        "    return(indices[:k])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QXP0EqlucnN3",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-3-1-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "This visible test prints the \"readable\" versions of the ten nearest neighbors to the grand mean review using `translate_review` from Step 0.2. Do you agree that these are acceptable \"average\" reviews?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nQ_JXEwJ2wFm",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-4-3-1",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "most_typical_indices = k_nearest_neighbors(X, [True]*len(X), grand_mean, 10)\n",
        "most_typical_reviews = lookup_docs(reviews_bow, most_typical_indices)\n",
        "for review in most_typical_reviews:\n",
        "    print(translate_review(review, reviews_dict))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uDfXa8KBkKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "most_typical_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmpzT535Ol-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 4.3.1: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"4.3.1\", answer = (most_typical_indices, most_typical_reviews))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y6aigeyBZkpj",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-3-2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Step 4.3.2 Implement VRC\n",
        "\n",
        "Complete the function `test_vrc(data, max_num_clusters)` that computes the $VRC$ for each value of k in `num_clusters`. Since we are passing in the data, compute a new grand mean within the function. However, since the grand mean does not depend on the clusters, you should not compute it within a loop. Please compute $SS_B$ using the grand mean, the cluster centers, and the assignments only (no additional libraries or built-in values). Just as a warning, it is expected that your $SS_W$ and $SS_B$ may not add up to exactly the same number every time, but the sum should not change too much.\n",
        "\n",
        "Additionally, please also compute a related ratio: \n",
        "\n",
        "$$\\eta^2 = \\frac{SS_B}{SS_B + SS_W}$$ \n",
        "\n",
        "This $\\eta^2$ (eta squared) is an effect size that pairs with your $VRC$ statistic. Basically all of the $VRC$s are statistically significant because we have so many data points. This is why the effect size is so important. The literature recommends an effect size of at least 0.12.\n",
        "\n",
        "The return statement is given because we would like to keep the $VRC$s and the $\\eta^2$s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tE7CZrN32wIN",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-4-3-2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 4.3.2\n",
        "def test_vrc(data, num_clusters):\n",
        "    #temp = pd.DataFrame(data)\n",
        "    #grand_mean = np.array(temp.mean(axis=0))\n",
        "    grand_mean = KMeans(n_clusters=1, init='k-means++', n_init=30, \n",
        "            tol=1e-4, random_state=1911, n_jobs=1).fit(data).cluster_centers_[0]\n",
        "    vrcs = []\n",
        "    etas_squared = []\n",
        "    for i in num_clusters:\n",
        "      km = KMeans(n_clusters=i, init='k-means++', n_init=30, \n",
        "                    tol=1e-4, random_state=1911, n_jobs=1).fit(data)\n",
        "      centers = km.cluster_centers_\n",
        "      labels =  km.labels_\n",
        "      ssb=0\n",
        "      for n in range(data.shape[0]):\n",
        "        for k in range(i):\n",
        "          if labels[n] == k:\n",
        "            diff = grand_mean-centers[k]\n",
        "            ssb = ssb + diff@diff.transpose()\n",
        "      ssw = km.inertia_\n",
        "      vrc = (ssb * (n-i)) / ( ssw * (i-1))\n",
        "      print(vrc)\n",
        "      vrcs.append(vrc)\n",
        "      eta_squared = ssb/(ssb + ssw)\n",
        "      etas_squared.append(eta_squared)\n",
        "    return vrcs, etas_squared\n",
        "\n",
        "#r_nk* np.subtract(grand_mean, centers[k]))@((np.subtract(grand_mean, centers[k])).transpose())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go_Vv6ITIb_E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4cf5db9a-3127-4a12-beb3-b00648929777"
      },
      "source": [
        "X.shape[0]"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s_5QvbFOf_7u",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-3-2-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "The code below takes a while to run just as the normal clustering before. I recommend printing the $VRC$ and $\\eta^2$ values as the come, so that you can track the progress."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BRk1XWzN2wKz",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-4-3-2-1",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "7a255626-ab27-46d7-9747-05a10bff3828"
      },
      "source": [
        "num_clusters = range(2,40)\n",
        "vrcs432, etas_squared432 = test_vrc(X, num_clusters)\n",
        "vrcs432 = list(map(lambda x: x.item(), vrcs432))\n",
        "etas_squared432 = list(map(lambda x: x.item(), etas_squared432))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4609.42164567439\n",
            "4600.122071901735\n",
            "4467.97980925367\n",
            "4300.25483633205\n",
            "4144.088170086031\n",
            "4032.8953155323857\n",
            "3961.675938386361\n",
            "3904.276901272512\n",
            "3871.1462092660804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFG-aK3OgWaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "km = KMeans(n_clusters=1, init='k-means++', n_init=30, \n",
        "                    tol=1e-4, random_state=1911, n_jobs=1).fit(X)\n",
        "centers = km.cluster_centers_\n",
        "type(centers[0])\n",
        "temp = pd.DataFrame(X)\n",
        "grand_mean = temp.mean(axis=0)\n",
        "type(np.array(grand_mean))\n",
        "diff = grand_mean-centers[0]\n",
        "diff@(diff.transpose())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE1GDpPO1zpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 4.3.2.1: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"4.3.2.1\", answer = (vrcs432, etas_squared432))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GBApDsWsJubS",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-3-3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Step 4.3.3: Select a number of clusters with VRC\n",
        "\n",
        "The code below prints rounded versions of the $VRC$s and $\\eta^2$s. Then, it plots the number of clusters (from 2 to 40) versus $VRC$. You do not need to modify this cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6Jqoq2NTXVcs",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-4-3-2-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "for i in range(len(num_clusters)):\n",
        "    print(\"%2d\"%num_clusters[i], \n",
        "          \"%d\"%np.round(vrcs432[i], 0), \n",
        "          np.round(etas_squared432[i], 2))\n",
        "\n",
        "plot_clusters(num_clusters, vrcs432)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iiJK2Y3EoeAw",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-4-3-3-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Much better, right??\n",
        "\n",
        "Complete the `best_vrc` function that compares and chooses a number of clusters based on the $VRC$s and $\\eta^2$s. Note that you are now looking for local maxima, so your elbow method should not be used again. Let's define a maximum as a point where the graph is increasing just before and decreasing just after. Return a list of all indices of `distortions` that are maxima. Then, these can be used to select $k$s from the `num_clusters` array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9iVFopkm2wNj",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-4-3-3",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 4.3.3\n",
        "# TODO: Complete the function\n",
        "def best_vrc(distortions):\n",
        "  indices=[]\n",
        "  #if (distortions[0]>distortions[1]):\n",
        "  #  indices.append(0)\n",
        "  for i in range(1,len(distortions)-1):\n",
        "    if distortions[i-1]<distortions[i]> distortions[i+1]:\n",
        "      indices.append(i)\n",
        "  #if distortions[len(distortions)-1] > distortions[len(distortions)-2]:\n",
        "  #  indices.append(len(distortions)-1)\n",
        "  return indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PSqtwSmRowZG",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-4-3-3",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "khat433 = [num_clusters[i] for i in best_vrc(vrcs432)]\n",
        "print(\"A good number of clusters is one of these:\", khat433)\n",
        "if ((min(khat433) < 2) or (max(khat433) > 39)):\n",
        "    raise ValueError('k hat is not in the right range')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2p7sLR8PFu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 4.3.3: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"4.3.3\", answer = khat433)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "016dNhVhiJha",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## Step 5: t-SNE\n",
        "\n",
        "In this last section, we are going to create a t-SNE plot that may help us decide how to use the clusters that we found in the previous section. More specifically, does k-means find differences between the reviews that are related to the star ratings, or other differences?\n",
        "\n",
        "We are going to use the clustering given below for this section. Double check that `X` is still the same as when you defined it in Step 4.0. You do not need to modify the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WBQp-W9VC2vT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cf31dd21-e9db-471a-9b16-8b183aed6911"
      },
      "source": [
        "km = KMeans(n_clusters=35, init='k-means++', n_init=30, max_iter=10, \n",
        "            tol=1e-4, random_state=1911, n_jobs=1)\n",
        "km.fit(X)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=10,\n",
              "       n_clusters=35, n_init=30, n_jobs=1, precompute_distances='auto',\n",
              "       random_state=1911, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t8EZ-Hcqi_rE",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-5-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 5.1: Exemplars of each cluster\n",
        "\n",
        "Let's begin by approaching this question in a somewhat qualitative way. Namely, let's find the nearest review to each cluster center. Complete the function below that iterates through the cluster centers of `km`. For each cluster center, call `k_nearest_neighbors`. Use the cluster assignments (labels) from `km` to construct the `mask` parameter for `k_nearest_neighbors`. The key idea here is that you want to search only through the reviews that were assigned to that cluster when searching for neighbors. It really should not change your answer, but it is a whole lot faster to do it this way. Alternatively, you could subset the dataset and pass in `[True]*(number_of_points_in_that_cluster)` as the mask, i.e. the mask has all true values, so no item is masked. But keeping track of indices is harder in that case.\n",
        "\n",
        "The function should return a list of lists of indices. There is one list per cluster center. Each index in one of these lists corresponds to a closest neighbor to a cluster center."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sa6Zmne-owe8",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-5-1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "12c32cf1-45b7-4f02-86fa-08b6a6f09145"
      },
      "source": [
        "# answer 5.1\n",
        "# TODO: Complete the function\n",
        "print(km.cluster_centers_[0])\n",
        "\n",
        "def get_exemplars(X_proj, km, n_exemplars):\n",
        "  labels=km.labels_\n",
        "  indices=[]\n",
        "  for i, center in enumerate(km.cluster_centers_):\n",
        "    mask = (labels == i)\n",
        "    nearest = k_nearest_neighbors(X_proj, mask, center, n_exemplars)\n",
        "    indices.append(nearest)\n",
        "  return indices"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.13476579 -0.0249031   0.02418579  0.01083826  0.05078947 -0.01593904\n",
            " -0.02160038  0.00861924  0.02807277 -0.01856998 -0.04703711  0.03557964\n",
            " -0.01168886  0.03297814  0.04400229  0.05094218  0.0086407  -0.02385692\n",
            " -0.05353694 -0.03708554 -0.01596838  0.02254608  0.00542662 -0.01897329\n",
            "  0.05667319 -0.00153924 -0.14361002  0.05228356  0.0785464   0.08192861\n",
            "  0.01465794  0.02772873 -0.02455467  0.05760076  0.02875002  0.0330672\n",
            "  0.02678156  0.09850691  0.03793111  0.06985202]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yzs_CAuOnIDn",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-5-1-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "The visible test cell below finds the indices of the nearest neighbors to each cluster center. Then it looks up the vectors for each of these indices and prints the readable version of each vector. Depending on your implementation this cell could take a long time. You do not need to modify this cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qmCeF6alowiU",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-5-1",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "f8b1c9fc-82bd-458e-d9c0-200b6eaa9420"
      },
      "source": [
        "exemplar_indices = get_exemplars(X, km, 1)\n",
        "exemplars = lookup_docs(reviews_bow, sum(exemplar_indices, []))\n",
        "for exemplar in exemplars:\n",
        "    print(translate_review(exemplar, reviews_dict))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kong kong toy toy day next bought go ear eat nylabon puppi rubber soft stick third threw trash\n",
            "larg will stuff go tank near product two love fish blood none ignor worm\n",
            "fast hard water even unfortun pick alreadi mar perman stain stain clr restor surfac\n",
            "better come much someth recommend live make junk within give made hour like bright red thought food food food food food food fish fish fish fish new new color color organ qualiti poop switch instead fake intern life life aisl constip pink spectrum spectrum vibrantli\n",
            "apart apart disappoint good good just much tri wast next next replac return sinc sinc amazon one one pet pet brown brown make light plu june piec piec piec receiv well chew give check got got like break break dark even product product thought cat cat smaller smaller soft larger purchas purchas dri dri sure compani mani finger differ differ differ packag packag packag packag packag packag packag moist seem anoth wonder safe consist natur natur pack pack pack pack vari finish previou crumbl crumbl joint content 2014i hip money.upd vermont vermont\n",
            "come someth toy dump know one review straight take well made anywher near ad see cut never trash food food bag buy contain etc read went chanc treat treat treat treat treat china china china china current current doberman doberman kill noth purina purina request safe respons convinc healthi wish petsmart hide stock glad petco plenti\n",
            "abl just just use work line cat never step jump mat dummi electrod\n",
            "just money money took will dog replac worth pet problem problem work work work broke fine stop extra extra spent top year even see small thought hair long though purchas purchas purchas purchas back brush brush look brand cleaner part part portion old anyway anoth anoth manufactur alreadi alreadi sell alway wrong bottom site told broken everyon machin wire vacuum vacuum vacuum vacuum vacuum vacuum repair belt connect spin spin fix shop hype kohl' lift\n",
            "dog use water water one die week enough like like top cat power compani consid motor motor properli act broken pressur fountain park rise\n",
            "away littl dog dog bought time got bag bag gave strip howev past mani love differ seem sick thrown promptli aroma discolor\n",
            "come disappoint good will dog dog worth made made product stick food question read china dog' qualiti control health chines toxic life edibl beyond non\n",
            "also came disappoint hard return defect order problem review work may receiv high refund product puppi yorki packag new follow older control immedi hope instruct minim minim terror\n",
            "away money much much play toy toy wast will day sinc time work get piec still made like like probabl cat cat cardboard threw interest look look happi mayb materi neither pay empti fun kitten roller grasp it'll tissu\n",
            "away just filter use use cat purchas gave realli guess hope critic fountain fountain\n",
            "order order get receiv receiv made last per amount amount amount product size size chang chang chang half differ attent box box box pay oz serv januari 16oz 32oz company'\n",
            "better hard remov will will pad pad pad pad pad pet pet time enough enough get get probabl thought cat hot hot never never cover cover interest way buy anyway caution heat heat heat heat afraid multipl hope instruct lie accord comfort pictur gener obvious worri fleec direct radiat penetr microwav overheat snugglesaf snugglesaf\n",
            "good much roll tri tri bark bark bark day dog put bought one cap get get get take got see see thought hot cover help possibl stuck calm calm calm calm lot mayb mayb mouth definit keep mean paw stay absolut busi eventu certainli floor worri altern crate crate freak agil halfway opposit panick trial\n",
            "littl money much remov remov one pet anyth like amount even outsid product product product red hair hair shed purchas purchas brush look save effect effect wors leav cloth cloth bit goldendoodl lint inferior spong spong fair\n",
            "away away destroy good hard just just dog regular sound sound sound amazon one recommend now six time week get take made made actual end hour hour like like product product product small long long need descript puppi stick stick stick stick stick frozen frozen purchas pound throw realli mayb less measur almost talk materi old stuf stuf stuf inch inch inch shred includ mere teeth teeth teeth idea idea known torn coupl longer crinkl approxim diamet ribbon ribbon ribbon silk eight dimens plastic-lik cool freezer freezer ici newfoundland rayon\n",
            "chewer come come kong let play toy tri dog recommend now expect stick minut love stuf liter qualiti anyon tough fetch\n",
            "came someth usual will one pad turn go goe straight made near cat cat purchas cheapli mani anim box post front failur scratch print peel scratcher\n",
            "apart larg larg larg think toy toy dog dog dog dog order recommend first well chew hour year product size larger almost old unless far somewhat joke purs\n",
            "apart bought puppi puppi keep area without effort gate gate knock enclos unstabl\n",
            "away came came fast larg much open think tri tri tri normal use use use whether recommend recommend run bottl bottl now time enough first get around can hour tank tank tank trash back look say two two happi extrem minut ill aquarium half half went dead effect place start treat fish fish fish fish kill kill kill alway blue tell healthi later green hide lost floor poison fin sign swim swim mislead jump valu repair worri dose dose dose dose dose dose prior surfac killer lay fire fire fire preciou terror agit eel eel eel eel errand mate melafix melafix melafix out.that potenc swam tale well.thes\n",
            "just dog work thing unfortun often diarrhea suffer glad folk dietari\n",
            "better come just just money money open will will know put return use whether worth worth worth decid one one one price price price recommend review terribl add time work go first flimsi piec piec piec around dollar extra got togeth want long long though cage cage cage cage cage cage cage cage cage cage purchas back buy feel gave look look look plastic possibl two find big big realli realli realli save save sever els hold least less model start start secur list base excit match box huge alreadi post absolut alway pack qualiti lower singl anyon properli lock mechan saw issu broken broken sit spend screw four door soon unit unit torn origin doubl doubl bit pictur thoroughli select tray inspect bent shape rust rusti room room compar websit bar ferret ferret ferret ferret ferret content nation nation nation nation assembl final solder shoddi cash comparison decis invest halfway critter debat crook feisti markedli midwest midwest midwest sacrific\n",
            "good just bought bought go get like outsid soft easi differ paw paw paw ever fit constantli especi tire concept retriev wipe sick bay chesapeak muddi trick task condom condom raini\n",
            "just tri day one anyth brown got smell two bone els attent pay three sit coupl picki wont untouch icki cocker spaniel slimi\n",
            "aggress chewer much supervis dog go want see cut gave realli went mouth notic dog' instantli sharp edg white comfort requir watch felt t-rex sat town\n",
            "come just larg larg someth dog dog dog dog dog normal one one pet review die now week go enough first first get still like even even even product see size thought found eat back bag bag look ill past past past lot lot mani mayb treat treat treat treat treat seem rate search star case report purina waggin enjoy continu toss death onlin recal rest quick quit sick forward confid news main hype specif suspicion complic\n",
            "dog return run made matter thing start booti stay soon tight fli trot\n",
            "hard dog dog dog know use pad time even product size size small fit pictur pictur true crate pillow represent\n",
            "abl also come design design design design fast great great hard insid just mix much much someth think tri tri tri tri will will will clean clean dog filter filter filter full full full full heard normal regular replac sinc sinc use use use use use use use use use use use use use water left left low one one pet pet pet pet pet pet pet pet pet problem problem problem run run make now time work work go go go go go batteri batteri batteri batteri batteri batteri enough enough first first first get get get get get may still take well actual actual around can can can can end end fill fill high high hour hour hour like like like like like like line spent spent thing top even product small small thought unfortun found found hair hair hair hair hair hair hair long need poor shed shed bed stick trash way back brush brush contain contain deal dri everi hand hand hand look pull pull pull shepherd two two minut minut power power power realli realli sure compani chang expens half lot lot mani sever sever type dead easi effect effect effect effect fairli fairli hold hold hold less less less less nice pill rather conveni conveni differ differ mean mean although although pass star attach attach attach base inch market point point leav strong easili might might appear appear appear awhil impress mention charg charg charg charg charg charg charg charg charg seen lower bottom tell devic head area area three three three call empti hous hous degre total anymor daili headach spend eventu cheap okay handl handl handl handl handl popular unit bare face origin corner floor floor floor floor floor floor carpet carpet carpet hardwood practic becom requir spot dust cord rug rug rug vacuum vacuum vacuum vacuum vacuum vacuum vacuum vacuum vacuum vacuum vacuum vacuum indic nickel advertis collaps basic introduc suction wrap consumpt connect cushion biggest spin swivel fulli dirt dirt lay warm real huski roller bissel bissel bissel bissel direct special special lift lift specif segment reach reach reach chair factor output flexibl techniqu juli consider upright outweigh cabl effici adapt crevic handheld handheld prone ultim decker mediocr dyson accumul recharg detach buster nicad nicad memori optima captur sofa vac vac vac vac vote ac ac cadmium dander devil disadvantag eureka full-siz hard-to-reach lift-off lift-off product.edit shaggi underpow underpow woefulli\n",
            "destroy favorit just just kong lb littl mix roll dog dog put bought review week work get around can fill small though interest look shepherd mayb bite easi treat morn seem set eventu hope coupl comfort butter peanut worri updat altern click hang fragil heeler zuke'\n",
            "apart just just littl littl littl put use use use bought bought decid horribl problem store go piec stop well got got togeth want bed way back manual lot often often easi els less love start pump pump pump pump pump pump pump pump pump pump night wound hous everyon figur origin wash fell easier ounc electr electr hook breastfeed ameda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQfj4WTHPcBe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "78f05e04-91c1-4993-da08-33b24dc1cbce"
      },
      "source": [
        "## AUTOGRADER Step 5.1: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"5.1\", answer = exemplar_indices)\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You earned 0/3 points.\n",
            "\n",
            "But, don't worry you can re-submit and we will keep only your latest score.\n",
            "               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "09MuIumNqkyU",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-5-2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 5.2: Prepare and run t-SNE\n",
        "\n",
        "The core idea of t-SNE is preserving the relative distances between all of the data points, but showing those distances in very few dimensions. As such, t-SNE compares every data point against every data point (Cartesian product). For the full dataset, that would be about 19 billion comparisons. So we can't do that.\n",
        "\n",
        "But, fortunately, you have already done a lot of work to cluster these data points. If we take a relatively large number of clusters and only consider 30 or so exemplars from each cluster, that should be small enough for t-SNE. The code below assembles the data subset for t-SNE using functions you have written before. Depending on your implementation this cell could take a long time. You do not need to modify this cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Drw0G08cPV4j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af8e5193-67a8-4310-e30b-20400277fdc8"
      },
      "source": [
        "exemplar_indices = get_exemplars(X, km, 30)\n",
        "exemplars = lookup_docs(reviews_tfidf, sum(exemplar_indices, []))\n",
        "for_tsne = densify(exemplars, len(reviews_dict))\n",
        "for_tsne.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(841, 18716)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-5-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "mrxCt43aLzBp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2dbb7d4f-2688-4b8b-9a03-f2970b6aaba0"
      },
      "source": [
        "## AUTOGRADER Step 5.2: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"5.2\", answer = (for_tsne.shape[0], for_tsne.shape[1]))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You earned 0/1 points.\n",
            "\n",
            "But, don't worry you can re-submit and we will keep only your latest score.\n",
            "               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DV2O5ITOtRws"
      },
      "source": [
        "The hyperparameters for t-SNE that I used to get a pretty picture are given below. All you need to do is look up the command to train the t-SNE model, which is given in the [API](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). Call your t-SNE vectors `embeddings_2d`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fb9lWlvaQDKT",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-5-2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 5.2\n",
        "# TODO: Run t-SNE\n",
        "tsne_model_2d = TSNE(perplexity=20, n_components=2, init='pca', n_iter=3500, random_state=1911)\n",
        "# TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XgfDd2btu1f4",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-5-3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Step 5.3: Color the points\n",
        "\n",
        "Some code to plot the t-SNE vectors is given below, but it won't look very pretty yet because we have not decided on a color scheme for the points. We will implement two options."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x8TBFcnGuzAI",
        "colab": {}
      },
      "source": [
        "def tsne_plot(embedding_clusters, a):\n",
        "    plt.figure(figsize=(16, 9))\n",
        "    colors = cm.rainbow(np.linspace(0, 1, len(embedding_clusters)))\n",
        "    for embeddings, color in zip(embedding_clusters, colors):\n",
        "        x = embeddings[:, 0]\n",
        "        y = embeddings[:, 1]\n",
        "        plt.scatter(x, y, c=[color]*len(x), alpha=a)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kUbdubT3vR2r",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-5-3-1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Step 5.3.1: By cluster membership\n",
        "\n",
        "The most straighforward choice would be to color a point according to the k-means cluster to which it was assigned. k-means is based on Euclidean distance and t-SNE is based on angular distance, so there should be some, but not total, consistency between the two algorithms.\n",
        "\n",
        "`get_exemplars` originally had a list of lists of indices, but these had to be flattened for `lookup_docs`. Therefore, you just need to re-group the points into clusters. There are exactly 30 points in each cluster, so there are many ways to do this. If you want an extra challenge, you can solve this part without using the magic number 30. But it is not required and will not affect your homework score.\n",
        "\n",
        "Call the re-grouped t-SNE vectors `embeddings`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hwjNAgVFySLu",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-5-3-1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 5.3.1\n",
        "# TODO: group the t-SNE embeddings by cluster membership\n",
        "embeddings = []\n",
        "# TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d9iZmqSYvKB_",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-5-3-1",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "tsne_plot(embeddings, 0.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRSYij6dWoma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 5.3.1: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"5.3.1\", answer = str(type(embeddings[0])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l1beI48Tw-KK",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-5-3-2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Step 5.3.2 By star rating\n",
        "\n",
        "Now as a finale, group the reviews by star rating. When you are done, `embeddings` should have a length of five. Then, redraw the plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qs9idX2wySN4",
        "nbgrader": {
          "grade": false,
          "grade_id": "answer-5-3-2",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "# answer 5.3.2\n",
        "# TODO: group the t-SNE embeddings by star rating\n",
        "embeddings = [[],[],[],[],[]]\n",
        "# TODO #"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oyDfy4i_QQUa",
        "nbgrader": {
          "grade": true,
          "grade_id": "visible-test-5-3-2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {}
      },
      "source": [
        "tsne_plot(embeddings, 0.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCdICmYrWenR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## AUTOGRADER Step 5.3.2: Run this to get your score. ##\n",
        "\n",
        "grader.grade(question_id = \"5.3.2\", answer = str(type(embeddings[0])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZbCFAGi_xdlX",
        "nbgrader": {
          "grade": false,
          "grade_id": "spec-5-3-3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "As you can see, the clusters formed by k-means and t-SNE do not seem to correspond to the star ratings. This pretty, but somewhat unhappy standpoint is where Homework 4 ends and your project begins.\n",
        "\n",
        "What kinds of analyses have we not tried? What structure is still hidden in these reviews? Can you infer how these 100,000 reviews were selected? Can something fancier than a random forest have higher accuracy in predicting the star rating?\n",
        "\n",
        "For your project, your task is to put together an interesting notebook about this dataset, similar to this one, the other homework notebooks from this class, or articles on [towardsdatascience.com](https://towardsdatascience.com/). The notebook should explain what you did in such a way that a non-technical person can read it. As such, your project will be manually graded as a work of data science communication. We hope that you can use your project notebook as something that you can show off in data science job interviews and the like. \n",
        "\n",
        "Congratulations on all of your work so far! Five stars for you!"
      ]
    }
  ]
}